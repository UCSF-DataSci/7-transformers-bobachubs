{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2372e098",
   "metadata": {},
   "source": [
    "# Part 2: Basic LLM Chat Tool\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this part, you'll create a simple command-line chat tool that interacts with a Large Language Model (LLM) through the Hugging Face API. This tool will allow you to have conversations with an LLM about healthcare topics.\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "- Connect to the Hugging Face API\n",
    "- Create a basic interactive chat loop\n",
    "- Handle simple error cases\n",
    "- Test with healthcare questions\n",
    "\n",
    "## Setup and Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5218f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "%pip install -r requirements.txt\n",
    "\n",
    "# Additional packages for LLM API interaction\n",
    "%pip install requests\n",
    "\n",
    "# Import necessary libraries\n",
    "import os\n",
    "import sys\n",
    "import requests\n",
    "import time\n",
    "import logging\n",
    "import argparse\n",
    "from typing import Optional\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Create directories\n",
    "os.makedirs('utils', exist_ok=True)\n",
    "os.makedirs('results/part_2', exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf14f17",
   "metadata": {},
   "source": [
    "## 1. Connecting to the Hugging Face API\n",
    "\n",
    "The Hugging Face Inference API provides access to many language models. We'll use models that are available on the free tier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a037581",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: HUGGINGFACE_API_KEY=***REMOVED***\n",
      "[{'generated_text': 'What are the symptoms of diabetes?\\n\\nDiabetes can vary widely in how it presents in individuals but ultimately, diabetes is a disease where the body has trouble with the uptake, utilization, or production of insulin. Insulin is a hormone produced by the pancreas that is present in small amounts in the bloodstream at all times to help the body store excess energy as fat or use its energy stores when we need them (food).\\n\\nIn diabetes, the body may not produce enough insulin, the body may not be able to utilize insulin efficiently, or the body may need too much insulin to perform its essential tasks. In any of these cases, blood sugar levels increase and can lead to a constellation of symptoms that are related to the many ways hyperglycemia (high blood sugar) can impact the body.\\n\\nThe most common symptoms associated with diabetes include thirst, increased urination (polyuria), weight loss, increased hunger (polyphagia), fatigue, blurry vision, and slow healing wounds or sores.\\n\\nThirst (Polydipsia): In diabetes, the excess sugar in the blood promotes water loss from the body through urine, causing dehydration. The bodyâ€™s response to dehydration is thirst.\\n\\nIncreased Urination (Polyuria): Due to the excess sugar in the blood, the kidneys attempt to filter the sugar out with water. As a result, more water is lost from the body through urination.\\n\\nWeight Loss: Often, individuals may report unexpected weight loss despite an increased appetite. The body may break down muscle and fat reserves to use as energy sources in the absence of adequate glucose, leading to weight loss.\\n\\nIncreased Hunger (Polyphagia): The body may crave food because of the hyperglycemia. This results in increased appetite but may not lead to weight gain because the body is breaking down muscle and fat reserves.\\n\\nFatigue: Due to the lack of energy sources in the body, individuals often report feeling tired or fatigued.\\n\\nBlurry Vision: The excess sugar in the blood can lead to a condition called diabetic retinopathy, where the blood vessels in the eye are damaged, causing blurriness or vision loss.\\n\\nSlow Healing Wounds: High blood sugar levels prevent the body from healing sores or wounds quickly. This can lead to infections that take longer to heal, opening up the potential for amputation, especially in the diabetic patient with previously damaged nerves and blood flow. A study found that 14-24% of all hospitalized diabetics experienced major amputations annually, citing foot ulcer as the main cause (Calayan et al., 2020). \\n\\nDiabetes is diagnosed based on a A1C test, which provides an average blood sugar level over the past 3 months, and fasting blood glucose levels, or the use of a glucometer to measure blood sugar levels at various times of the day. The ADA recommends treating diabetes early and aggressively, as complications from diabetes, such as renal failure, cardiovascular disease, blindness, and neuropathy, can have devastating effects on overall health and well-being (American Diabetes Association, 2019).\\n\\nThe increasing prevalence of diabetes, coupled with the disproportionately alarming consequences among low-income and underserved populations, highlights the need for efforts to address this public health challenge through education about healthy living, lifesyle modifications, and ongoing care by healthcare professionals and community resources (Becker et al., 2019). \\n\\nCalayan, B. J., Damron, M., Maddy, S., & Orberg, M. L. (2020). Major Amputation and Lower Extremity Ulcerations in Diabetes Patients: Associations Between Virulence Factors and ARDS Presence. Major amputation and lower extremity ulcerations in diabetes patients associations between virulence factors and ards presence, 6(3), e007613. Doi:10.3390/diabetes1007613\\n\\nAmerican Diabetes Association (ADA) (2019). Standards of Medical Care in Diabetes 2019. Diabetes Care, 42(Suppl 1), S1-S217. Doi: 10.2337/dc19-S001\\n\\nBecker, R., Palermo, J. R., Kranzer, R. R., & Wang, D. (2019). Spatial analysis of diabetes in Michigan: understanding incidence and prevalence patterns to inform interventions. Preventive Medicine, 87(3), 341-347. Doi: 10.1016/j.ypmed.2018.11.013'}]\n"
     ]
    }
   ],
   "source": [
    "# Example of a simple API request to Hugging Face\n",
    "import requests\n",
    "import os\n",
    "\n",
    "API_URL = \"https://api-inference.huggingface.co/models/HuggingFaceH4/zephyr-7b-beta\"\n",
    "\n",
    "API_KEY = 'hf_XXXXXXXXXXXXXXXXX'\n",
    "\n",
    "headers = {\"Authorization\": f\"Bearer {API_KEY}\"}  # Optional for some models\n",
    "\n",
    "def query(payload):\n",
    "    \"\"\"\n",
    "    Send a query to the Hugging Face API\n",
    "    \n",
    "    Args:\n",
    "        payload: Dictionary containing the query parameters\n",
    "        \n",
    "    Returns:\n",
    "        The API response\n",
    "    \"\"\"\n",
    "    # TODO: Implement the API request\n",
    "    # Use requests.post to send the query to the API_URL\n",
    "    response = requests.post(API_URL, headers=headers, json=payload)\n",
    "    result = response.json()\n",
    "    # Return the response\n",
    "    return result\n",
    "\n",
    "# Test the query function\n",
    "test_payload = {\"inputs\": \"What are the symptoms of diabetes?\"}\n",
    "response = query(test_payload)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a2c820",
   "metadata": {},
   "source": [
    "## 2. Creating Simple Chat Scripts (in utils/one_off_chat.py)\n",
    "\n",
    "Your task is to create two simple scripts that interact with the Hugging Face API:\n",
    "\n",
    "1. A basic one-off chat script (`utils/one_off_chat.py`)\n",
    "2. A contextual conversation script (`utils/conversation.py`)\n",
    "\n",
    "### One-Off Chat Script\n",
    "\n",
    "Create a script that handles independent interactions (each prompt/response is separate):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0d63de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# utils/one_off_chat.py\n",
    "\n",
    "import requests\n",
    "import argparse\n",
    "import os\n",
    "\n",
    "def get_response(prompt, model_name=\"google/flan-t5-base\", api_key=None):\n",
    "    \"\"\"\n",
    "    Get a response from the model\n",
    "    \n",
    "    Args:\n",
    "        prompt: The prompt to send to the model\n",
    "        model_name: Name of the model to use\n",
    "        api_key: API key for authentication (optional for some models)\n",
    "        \n",
    "    Returns:\n",
    "        The model's response\n",
    "    \"\"\"\n",
    "    # TODO: Implement the get_response function\n",
    "    # Set up the API URL and headers\n",
    "    # Create a payload with the prompt\n",
    "    # Send the payload to the API\n",
    "    # Extract and return the generated text from the response\n",
    "    # Handle any errors that might occur\n",
    "    pass\n",
    "\n",
    "def run_chat():\n",
    "    \"\"\"Run an interactive chat session\"\"\"\n",
    "    print(\"Welcome to the Simple LLM Chat! Type 'exit' to quit.\")\n",
    "    \n",
    "    while True:\n",
    "        user_input = input(\"\\nYou: \")\n",
    "        if user_input.lower() == 'exit':\n",
    "            print(\"Goodbye!\")\n",
    "            break\n",
    "            \n",
    "        # TODO: Get response from the model\n",
    "        # Print the response\n",
    "        \n",
    "def main():\n",
    "    parser = argparse.ArgumentParser(description=\"Chat with an LLM\")\n",
    "    # TODO: Add arguments to the parser\n",
    "    \n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    # TODO: Run the chat function with parsed arguments\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b45493",
   "metadata": {},
   "source": [
    "### Contextual Conversation Script\n",
    "\n",
    "Create a script that maintains conversation history:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b413e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# utils/conversation.py\n",
    "\n",
    "import requests\n",
    "import argparse\n",
    "import os\n",
    "\n",
    "def get_response(prompt, history=None, model_name=\"\", api_key=None, history_length=3):\n",
    "    \"\"\"\n",
    "    Get a response from the model using conversation history\n",
    "    \n",
    "    Args:\n",
    "        prompt: The current user prompt\n",
    "        history: List of previous (prompt, response) tuples\n",
    "        model_name: Name of the model to use\n",
    "        api_key: API key for authentication\n",
    "        history_length: Number of previous exchanges to include in context\n",
    "        \n",
    "    Returns:\n",
    "        The model's response\n",
    "    \"\"\"\n",
    "    # TODO: Implement the contextual response function\n",
    "    # Initialize history if None\n",
    "    if history is None:\n",
    "        history = []\n",
    "        \n",
    "    # TODO: Format a prompt that includes previous exchanges\n",
    "    # Get a response from the API\n",
    "    # Return the response\n",
    "    pass\n",
    "\n",
    "def run_chat():\n",
    "    \"\"\"Run an interactive chat session with context\"\"\"\n",
    "    print(\"Welcome to the Contextual LLM Chat! Type 'exit' to quit.\")\n",
    "    \n",
    "    # Initialize conversation history\n",
    "    history = []\n",
    "    \n",
    "    while True:\n",
    "        user_input = input(\"\\nYou: \")\n",
    "        if user_input.lower() == 'exit':\n",
    "            print(\"Goodbye!\")\n",
    "            break\n",
    "            \n",
    "        # TODO: Get response using conversation history\n",
    "        # Update history\n",
    "        # Print the response\n",
    "        \n",
    "def main():\n",
    "    parser = argparse.ArgumentParser(description=\"Chat with an LLM using conversation history\")\n",
    "    # TODO: Add arguments to the parser\n",
    "    \n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    # TODO: Run the chat function with parsed arguments\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d46d55d",
   "metadata": {},
   "source": [
    "## 3. Testing and Evaluation\n",
    "\n",
    "Create a script to test your chat implementations with specific healthcare questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c355a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# utils/test_chat.py\n",
    "\n",
    "import os\n",
    "import csv\n",
    "from pathlib import Path\n",
    "\n",
    "# Import our chat modules - since we're in the same directory\n",
    "from one_off_chat import get_response as get_one_off_response\n",
    "# Optionally import the conversation module if testing that too\n",
    "# from conversation import get_response as get_contextual_response\n",
    "\n",
    "def test_chat(questions, model_name=\"google/flan-t5-base\", api_key=None):\n",
    "    \"\"\"\n",
    "    Test the chat function with a list of questions\n",
    "    \n",
    "    Args:\n",
    "        questions: A list of questions to test\n",
    "        model_name: Name of the model to use\n",
    "        api_key: API key for authentication\n",
    "        \n",
    "    Returns:\n",
    "        A dictionary mapping questions to responses\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    for question in questions:\n",
    "        print(f\"Testing question: {question}\")\n",
    "        # Get response using the one-off chat function\n",
    "        response = get_one_off_response(question, model_name, api_key)\n",
    "        results[question] = response\n",
    "        \n",
    "    return results\n",
    "\n",
    "# List of healthcare questions to test\n",
    "test_questions = [\n",
    "    \"What are the symptoms of gout?\",\n",
    "    \"How is gout diagnosed?\",\n",
    "    \"What treatments are available for gout?\",\n",
    "    \"What lifestyle changes can help manage gout?\",\n",
    "    \"What foods should be avoided with gout?\"\n",
    "]\n",
    "\n",
    "def save_results(results, output_file=\"results/part_2/example.txt\"):\n",
    "    \"\"\"\n",
    "    Save the test results to a file\n",
    "    \n",
    "    Args:\n",
    "        results: Dictionary mapping questions to responses\n",
    "        output_file: Path to the output file\n",
    "    \"\"\"\n",
    "    with open(output_file, 'w') as f:\n",
    "        # Write header\n",
    "        f.write(\"# LLM Chat Tool Test Results\\n\\n\")\n",
    "        \n",
    "        # Write usage examples\n",
    "        f.write(\"## Usage Examples\\n\\n\")\n",
    "        f.write(\"```bash\\n\")\n",
    "        f.write(\"# Run the one-off chat\\n\")\n",
    "        f.write(\"python utils/one_off_chat.py\\n\\n\")\n",
    "        f.write(\"# Run the contextual chat\\n\")\n",
    "        f.write(\"python utils/conversation.py\\n\")\n",
    "        f.write(\"```\\n\\n\")\n",
    "        \n",
    "        # Write test results\n",
    "        f.write(\"## Test Results\\n\\n\")\n",
    "        f.write(\"```csv\\n\")\n",
    "        f.write(\"question,response\\n\")\n",
    "        \n",
    "        for question, response in results.items():\n",
    "            # Format the question and response for CSV\n",
    "            q = question.replace(',', '').replace('\\n', ' ')\n",
    "            r = response.replace(',', '').replace('\\n', ' ')\n",
    "            f.write(f\"{q},{r}\\n\")\n",
    "            \n",
    "        f.write(\"```\\n\")\n",
    "\n",
    "# Run the test and save results\n",
    "if __name__ == \"__main__\":\n",
    "    results = test_chat(test_questions)\n",
    "    save_results(results)\n",
    "    print(\"Test results saved to results/part_2/example.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67174805",
   "metadata": {},
   "source": [
    "## Progress Checkpoints\n",
    "\n",
    "1. **API Connection**:\n",
    "   - [ ] Successfully connect to the Hugging Face API\n",
    "   - [ ] Send a query and receive a response\n",
    "   - [ ] Handle API errors gracefully\n",
    "\n",
    "2. **Chat Function Implementation**:\n",
    "   - [ ] Implement the get_response function\n",
    "   - [ ] Create the run_chat function for interactive sessions\n",
    "   - [ ] Handle errors and edge cases\n",
    "\n",
    "3. **Command Line Interface**:\n",
    "   - [ ] Create a parser with appropriate arguments\n",
    "   - [ ] Implement the main function\n",
    "   - [ ] Test the CLI functionality\n",
    "\n",
    "4. **Testing and Evaluation**:\n",
    "   - [ ] Test the functions with healthcare questions\n",
    "   - [ ] Save the results in a structured format\n",
    "   - [ ] Analyze the quality of responses\n",
    "\n",
    "## Common Issues and Solutions\n",
    "\n",
    "1. **API Access Issues**:\n",
    "   - Problem: Rate limiting\n",
    "   - Solution: Implement exponential backoff and retry logic\n",
    "   - Problem: Authentication errors\n",
    "   - Solution: Verify API key and environment variables\n",
    "\n",
    "2. **Response Parsing Issues**:\n",
    "   - Problem: Unexpected response format\n",
    "   - Solution: Add error handling for different response structures\n",
    "   - Problem: Empty or error responses\n",
    "   - Solution: Provide meaningful fallback responses\n",
    "\n",
    "3. **CLI Issues**:\n",
    "   - Problem: Arguments not parsed correctly\n",
    "   - Solution: Test with different argument combinations\n",
    "   - Problem: Script not executable\n",
    "   - Solution: Check file permissions\n",
    "\n",
    "## What to Submit\n",
    "\n",
    "1. Your implementation of the chat scripts:\n",
    "   - Basic requirement: `utils/one_off_chat.py` for single prompt/response chat\n",
    "   - Stretch goal (optional): `utils/conversation.py` for contextual chat\n",
    "   - Testing script: `utils/test_chat.py` to evaluate your implementation\n",
    "\n",
    "2. Test results in `results/part_2/example.txt` with the following format:\n",
    "   - Usage examples section showing how to run your scripts\n",
    "   - Test results section with CSV-formatted question/response pairs\n",
    "   - If you implemented the stretch goal, include examples of contextual exchanges\n",
    "\n",
    "The auto-grader should check:\n",
    "1. That your chat scripts can be executed\n",
    "2. That they correctly handle the test questions\n",
    "3. That your results file contains the required sections"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "sarahli",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
